---
# 论文完整标题
title: 'Visual Speech Recognition in Natural Scenes Based on Sptial Transformer Networks'

# 论文作者，此处仅需填写本实验室成员（包括王老师）即可，使用中文姓名
authors:
  - 余金
  - 王士林

# 论文发表时间，年-月-日，大致即可
date: '2020-10-01'

# 论文类型， 可选：conference, journal
publication_types: ['conference']

# 会议/期刊名称及缩写
publication: In *Proceedings of IEEE International Conference on Anti-counterfeiting, Security, and Identification 2020*
publication_short: In *ASID 2020*

# 论文摘要，不要有换行
abstract: In this paper, we improve the performance of visual speech recognition in natural scenes based on spatial transformer networks. Visual speech recognition can be applied to authentication systems for liveness detection to avoid replay attacks and ensure security. Identity authentication based on visual speech recognition may be conducted anywhere on portable electronic devices. However, a great number of variations exist in natural scenes including diverse speakers' poses, different distances towards the camera, occasional quiver of the lips, etc., which bring tremendous troubles for the recognition, leading to poorer performance of the authentication system. In view of the challenges, we introduce the spatial transformer networks (STN), which can help deal with variations, especially in complex natural scenes. Considering the characteristics of the lip feature, a new transformation network is proposed, which fuses the temporal and spatial information to generate transformation parameters. The well-designed network can be simply inserted into existing visual speech recognition approaches to implement end-to-end training. By taking temporal dependencies into consideration, a better transformation is performed to normalize the lip image sequences and difficulties of visual speech recognition in natural scene can thus be reduced, which is beneficial to the identity authentication system to enhance security. From the experimental results, it is demonstrated that a decreased word error rate can be achieved, particularly in natural scenes, when our approach is adopted.

# 后续内容无需修改
url_pdf: ''
---