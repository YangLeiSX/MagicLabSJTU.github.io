---
# 论文完整标题
title: 'Speaker-Independent Lipreading with Limited Data'

# 论文作者，此处仅需填写本实验室成员（包括王老师）即可，使用中文姓名
authors:
  - 杨晨照
  - 张兴璇
  - 王士林

# 论文发表时间，年-月-日，大致即可
date: '2020-10-01'

# 论文类型， 可选：conference, journal
publication_types: ['conference']

# 会议/期刊名称及缩写
publication: In *Proceedings of IEEE International Conference on Image Processing 2020*
publication_short: In *ICIP 2020*

# 论文摘要，不要有换行
abstract: Recent researches have demonstrated that with a huge annotated training dataset, some sophisticated automatic lipreading methods perform even better than a professional human lip reader. However, when the training set is limited, i.e. containing a few number of speakers, most existing lipreading approaches cannot provide accurate recognition results for unseen speakers due to the inter-speaker variability. To improve the lipreading performance in the speaker-independent scenario, a new deep neural network (DNN) is proposed in this paper. The proposed network is composed of two parts, i.e. the Transformer-based Visual Speech Recognition Network (TVSR-Net) and the Speaker Confusion Block (SC-Block). The TVSR-Net is designed to extract lip features and recognize the speech. The SC-Block aims to achieve speaker normalization by eliminating the influence of various talking styles/habits. A Multi-Task Learning (MTL) scheme is designed for network optimization. Experiment results on the GRID dataset have demonstrated the effectiveness of the proposed network on speaker-independent recognition with limited training data.

# 后续内容无需修改
url_pdf: ''
---