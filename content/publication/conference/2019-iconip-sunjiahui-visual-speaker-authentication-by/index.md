---
# 论文完整标题
title: 'Visual Speaker Authentication by a CNN-Based Scheme with Discriminative Segment Analysis'

# 论文作者，此处仅需填写本实验室成员（包括王老师）即可，使用中文姓名
authors:
  - 孙佳慧
  - 王士林

# 论文发表时间，年-月-日，大致即可
date: '2019-10-01'

# 论文类型， 可选：conference, journal
publication_types: ['conference']

# 会议/期刊名称及缩写
publication: In *Proceedings of International Conference on Neural Information Processing 2019*
publication_short: In *ICONIP 2019*

# 论文摘要，不要有换行
abstract: Recent research shows that the static and dynamic features of a lip utterance contain abundant identity-related information. In this paper, a new deep convolutional neural network scheme is proposed. The entire lip utterance is first divided into a series of overlapping segments; then an adaptive scheme is designed to automatically examine the dis- criminative power and assign a corresponding weight of each segment in the entire utterance. The final authentication result of the entire utter- ance is determined by weighted voting of the results for all the segments. In addition, considering the various lighting condition in the natural envi- ronment, an illumination normalization procedure is proposed. Experi- mental results show that different segments of the same utterance have different discriminative power for user authentication, and focusing on the discriminative details will be more effective. The proposed method has shown superior performance compared with two state-of-the-art lip authentication approaches investigated.

# 后续内容无需修改
url_pdf: ''
---