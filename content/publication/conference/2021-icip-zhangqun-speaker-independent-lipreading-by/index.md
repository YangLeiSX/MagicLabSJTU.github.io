---
# 论文完整标题
title: 'Speaker-Independent Lipreading by Disentangled Representation Learning'

# 论文作者，此处仅需填写本实验室成员（包括王老师）即可，使用中文姓名
authors:
  - 张群
  - 王士林

# 论文发表时间，年-月-日，大致即可
date: '2021-10-01'

# 论文类型， 可选：conference, journal
publication_types: ['conference']

# 会议/期刊名称及缩写
publication: In *Proceedings of IEEE International Conference on Image Processing 2021*
publication_short: In *ICIP 2021*

# 论文摘要，不要有换行
abstract: With the development of the deep learning technology, automatic lipreading based on deep neural network can achieve reliable results for speakers appeared in the training dataset. However, speaker-independent lipreading, i.e. lipreading for unseen speakers, is still a challenging task, especially when the training samples are quite limited. To improve the recognition performance in the speaker- independent scenario, a new deep neural network structure, named Disentangled Visual Speech Recognition Network (DVSR-Net), is proposed in this paper. DVSR-Net is designed to disentangle the identity-related features and the content-related features from the lip image sequence. To further eliminate the identity information that remained in the content features, a content feature refinement stage is designed in network optimization. By this way, the extracted features are closely related to the content information and irrelevant to the various talking style and thus the speech recognition performance for unseen speakers can be improved. Experiments on two widely used datasets have demonstrated the effectiveness of the proposed network in the speaker-independent scenario.

# 后续内容无需修改
url_pdf: ''
---