---

# 论文完整标题

title: 'Preventing DeepFake Attacks on Speaker Authentication by Dynamic Lip Movement Analysis'

# 论文作者，此处仅需填写本实验室成员（包括王老师）即可，使用中文姓名

authors:

- 杨晨照
- 马骏
- 王士林

# 论文发表时间，年-月-日，大致即可

date: '2021-01-05'

# 论文类型， 可选：conference, journal

publication_types: ['journal']

# 会议/期刊名称及缩写

publication: In *IEEE Transactions on Information Forensics and Security*
publication_short: In *IEEE TIFS*

# 论文摘要，不要有换行

abstract: Recent research has demonstrated that lip-based speaker authentication systems can not only achieve good authen- tication performance but also guarantee liveness. However, with modern DeepFake technology, attackers can produce the talking video of a user without leaving any visually noticeable fake traces. This can seriously compromise traditional face-based or lip-based authentication systems. To defend against sophisticated DeepFake attacks, a new visual speaker authentication scheme based on the deep convolutional neural network (DCNN) is proposed in this paper. The proposed network is composed of two functional parts, namely, the Fundamental Feature Extraction network (FFE-Net) and the Representative lip feature extraction and Classification network (RC-Net). The FFE-Net provides the fundamental information for speaker authentication. As the static lip shape and lip appearance is vulnerable to DeepFake attacks, the dynamic lip movement is emphasized in the FFE- Net. The RC-Net extracts high-level lip features that discriminate against human imposters while capturing the client’s talking style. A multi-task learning scheme is designed, and the proposed network is trained end-to-end. Experiments on the GRID and MOBIO datasets have demonstrated that the proposed approach is able to achieve an accurate authentication result against human imposters and is much more robust against DeepFake attacks compared to three state-of-the-art visual speaker authentication algorithms. It is also worth noting that the proposed approach does not require any prior knowledge of the DeepFake spoofing method and thus can be applied to defend against different kinds of DeepFake attacks.

# 后续内容无需修改

url_pdf: ''
---